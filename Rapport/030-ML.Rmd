
# Modélisation de la probabilité de fusionner

<!-- ```{r} -->
<!-- load("../Base.RData") -->
<!-- ``` -->


Après nettoyage et sélection des features, la base de données pour exécuter le machine learning est donc constituée de 109082 observations et de 38 variables explicatives.

```{r}
names(baseML[,-39])
```

On découpe cette base en 12 blocs de lignes qui vont permettre de réaliser la validation croisée. On a également implémenté une fonction qui permet d'entrainer puis de tester les modèles suivants :

- régression logistique
- régression logistique avec choix de variables par AIC (step)
- régressions pénalisées (lasso, ridge, elasticnet)
- arbre de décision
- boosting (adaboost)
- forêt aléatoire
- SVM (mais n'ont pas abouti)
- Réseaux de neurones
    + 3 couches connectées de façon complète avec respectivement 10, 20 et 10 neurones
    + 4 couches connectées de façon complète avec respectivement 1024, 640, 120 et 12 neurones

La fonction est appelée dans une boucle `foreach` qui permet de paraléliser les traitements pour chaque bloc. On a ainsi pu diviser les temps de calcul par 3 (pour les modèles entrainés sur nos postes) ou par 7 (pour les modèles entraînés sur un serveur).
Le résultat de cette boucle est un dataframe contenant les prévisions (probabilités) faites par les différents modèles sur les blocs de tests.

Les résultats sont présentés dans l'application shiny dédiée au projet (courbes ROC, indicateur AUC et matrices de confusion).


<!-- Globalement, on constate que les modèles à base d'arbres de décisions donnent de meilleurs résultat : il semble que le choix de fusionner soit déterministe, et guidé par des pratiques ancrées de travail en commun de la part des commune : ce sont l'appartenance au même EPCI en 2014 -->