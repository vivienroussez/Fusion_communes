[
["index.html", "Prévoir les fusions de communes Chapitre 1 Introduction", " Prévoir les fusions de communes Groupe des gauchistes 2018-03-14 Chapitre 1 Introduction En 2015, le projet de loi sur l’amélioration de la commune nouvelle est adopté. La même année, la loi pour une Nouvelle Organisation territoriale de la République (Notr) renforce les compétences des Régions et établissement publics de coopération intercommunale (EPCI, soit les communautés d’agglomération, de communes, etc…). Ces mesures interviennent dans un contexte de réformé territoriale visant à rationaliser les dotations de l’Etat afin d’augmenter la capacité des régions à entrer dans la compétition internationale, et de ernforcer la coopération entre communes afin de développer la mutualisation des services et réaliser des économies d’échelle. En plus de ces mesures, la loi concernant les communes nouvelles incite les communes, notamment les petites, à fusionner, avec une incitation fiscale assez forte : alors que les dotations baissent de façon génrale, les communes ayant fusionnée voient leurs dotations gelées pour 3 ans. De fait, on compte 36 517 communes en 2015, avant la promulgation de la loi body {text-align: justify} "],
["un-proxy-de-la-couleur-politique-dune-commune.html", "Chapitre 2 Un proxy de la couleur politique d’une commune", " Chapitre 2 Un proxy de la couleur politique d’une commune Pour alimenter le modèle de machine learning, une variable qui semble, a priori, très importante, est la proximité politique entre chaque couple de communes ; on peut penser que si les mairies, avant la fusion, ont des couleurs semblables, la probabilité d’un accord de fusion entre les deux communes est plus grande. N’ayant à disposition aucune donnée vraiment structurée concernant la couleur politique de telle ou telle mairie, nous avons opté pour l’analyse des résultats des élections présidentielles du premier tour de 2017. L’hypothèse est que les votes des électeurs lors de l’élection nationale donne un proxy raisonnable de l’orientation locale. Cette hypothèse est naturellement simplificatrice et n’est pas valable partout (implantation locale d’une personnalité, absence d’étiquette des élus locaux…). Les données sont disponibles sur data.gouv.fr et proviennent du ministère de l’intérieur. Le choix s’est porté sur le premier tour dans la mesure où celui-ci contient plus de variance, puisque davantage de candidats. "],
["preparation-des-donnees.html", "Chapitre 3 Préparation des données", " Chapitre 3 Préparation des données Avant de démarrer, il faut installer le package COGugaison, qui permet de passer facilement d’un millésime de géographique comunale à un autre. On charge en plus les packages du tidyverse, FactoMineR pour l’analyse des données, et sf pour la gestion des données géographiques. On charge également le fonds de carte communale de l’IGN. Pour le fonds de carte, il faut passer des arrondissements (Paris, Lyon, Marseille) à la commune (on ne dispose pas des informations à l’arrondissement dans la plupart des cas) ## Reading layer `COMMUNE&#39; from data source `/Volumes/BIGUSB/Datascience/Projet/Fusion_communes/Sources/COMMUNE.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 36571 features and 18 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 99217.1 ymin: 6049646 xmax: 1242417 ymax: 7110480 ## epsg (SRID): NA ## proj4string: +proj=lcc +lat_1=44 +lat_2=49 +lat_0=46.5 +lon_0=3 +x_0=700000 +y_0=6600000 +ellps=GRS80 +units=m +no_defs Les données initiales se présentent comme un fichier de 36000 lignes avec pour chaque candidats 7 colonnes donnant notamment le nom, prénom, nombre de voix et les pourcentages correspondants. Le premier travail consiste à passer de ce format “large” inexploitable à un format “long” qui aura un ligne pour chaque croisement commune*candidat avec en colonne le nombre de voix. On gère également le millésime du COG en se ramenant au COG2015 comme pour les autres variables que l’on ajoute par la suite. "],
["analyse-factorielle-des-resultats.html", "Chapitre 4 Analyse factorielle des résultats", " Chapitre 4 Analyse factorielle des résultats Maintenant que nous disposons d’une table exploitable, on peut réaliser une analyse factorielle pour pouvoir synthétiser le positionnement politique des communes. Pour cela, on effectue une analyse factorielle des correspondance, puisqu’on dispose de 2 variables qualitatives : la commune (individus lignes dans le tableau de contingence) et le candidat (individus colonne). D’après l’histogramme des valeurs propres, on voit que l’inertie du tableau de contingence est très concentrée sur les 2 premiers axes factoriels, à hauteur de 70%. Le critère du point d’inflexion conduirait à retenir les 4 premiers axes (la dérivée seconde change de signe au niveau de la 4e valeur propre), pour 87% de l’inertie totale. On observe un effet Guttman assez net sur le premier plan factoriel : on a une opposition nette entre les candidats extrêmes à droite et les candidats “modérés” sur la gauche. Le second axes semble davantage retracer le clivage gauche-droite, avec les candidats Macron et Le Pen proche du barycentre. Le dexième plan factoriel donne lui à voir des différences moins structurantes à l’échelle nationale, mais on voit nettement la particularité “locale” du vote Lassalle, ainsi que (dans une moindre mesure) de celui en faveur de Dupont-Aignan. La représentation cartographique de ces axes factoriels : "],
["synthese-typologie-communale.html", "Chapitre 5 Synthèse : typologie communale", " Chapitre 5 Synthèse : typologie communale Pour la suite des opérations (modélisation de fusion/ non fusion), nous allons garder les 4 variables quantitatives obtenues par l’AFC mais pour pousser la démarche jusqu’au bout, nous réalisons une classification (clustering) des communes à partir des coordonnées factorielles obtenues. Etant donnés le nombre d’individus et le manque de puissance de la machine sur laquelle je travaille (4Go de RAM), une CAH est impossible (sauf à faire un premier k-means pour diminuer la dimension…), nous réalisons donc un clustering avec l’algorithme k-means puis dbscan Le gain de variance inter-classes augmente très rapidement quand on agmente le nombre de classe, mais le gain marginal s’atténue assez rapidement. On retient donc 5 classes, qui retracent près de 60% de la variance totale des quatre variables. "]
]
