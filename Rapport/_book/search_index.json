[
["index.html", "Prévoir les fusions de communes Chapitre 1 Introduction 1.1 Pourquoi ce sujet ? 1.2 Pourquoi pas les autres ?", " Prévoir les fusions de communes Eglantine Bigot-Haon, Vivien Roussez, Khouloud Zine Elabidine aka les datagourdes 2018-03-28 Chapitre 1 Introduction 1.1 Pourquoi ce sujet ? En 2015, le projet de loi sur l’amélioration de la commune nouvelle est adopté. La même année, la loi pour une Nouvelle Organisation territoriale de la République (Notr) renforce les compétences des Régions et établissement publics de coopération intercommunale (EPCI, soit les communautés d’agglomération, de communes, etc…). Ces mesures interviennent dans un contexte de réformé territoriale visant à rationaliser les dotations de l’Etat afin d’augmenter la capacité des régions à entrer dans la compétition internationale, et de ernforcer la coopération entre communes afin de développer la mutualisation des services et réaliser des économies d’échelle. Par ailleurs, la France, avec près de 36 800 communes en 2015, regroupe à elle seule un tiers des communes de l’Union européenne. La plupart sont très petites (voir shiny), ce qui limite de fait les capacités d’action. C’est pourquoi, en plus de la loi NOTR, une loi concernant les communes nouvelles a été adoptée en 2015, et incite les communes, notamment les petites, à fusionner, avec une incitation fiscale assez forte : alors que les dotations de l’Etat baissent de façon générale, les communes ayant fusionnée voient leurs dotations gelées pour 3 ans. Depuis l’adoption de cette loi, on comptabilise près de 1750 fusions de communes, ce qui représente une baisse significative du nombre de collectivité, même si cela reste relativement modeste par rapport à la baisse du nombre de municipalités dans les autres pays européens, amorcée dès 1950 (jusqu’à -92 % au Danemark !). 1.2 Pourquoi pas les autres ? Nous avions commencer à travailler sur deux autres sujets : La réutilisation des jeux de données mis à disposition sur data.gouv.fr Travail su le traffic et les accidents dans Paris à partir des données de opendata.paris.fr Pour le premier sujet, nous avons reculé après avoir constaté que les fichiers mis à disposition changeaient tous les jours, et surtout était systématiquement incomplets (manque de lignes). Sur le second sujet, la difficulté était de trouver un “individu statistique”&quot; sur lequel faire nos modélisation. Certaines données étaient géocodées au “tronçon”, d’autres à la rue, d’autres à l’XY… Le temps de traitement de la donnée aurait été trop important. "],
["contitution-de-la-base-de-donnees.html", "Chapitre 2 Contitution de la base de données 2.1 Création des couples de communes 2.2 Indicateurs communaux mobilisés 2.3 Indicateurs de flux 2.4 Appartenance à un même périmètre 2.5 Détermination de la couleur politique des communes 2.6 Synthèse : Dictionnaire des variables 2.7 Imputations et corrections 2.8 Calcul de l’indicateur de fusion", " Chapitre 2 Contitution de la base de données Pour nourrir le modèle de machine learning, nous avons procédé en plusieurs étapes : Identification des couples de communes contigües (seules susceptibles de fusionner) Constitution d’indicateurs de dissimilarités pour chacun de ces couples Collecte d’indicateurs communaux donnant les caractéristiques démographiques, sociales, économiques des territoire Calcul de la distance entre chacun des couples sur la base de chacun de ces indicateurs. La distance est calculée par la formule \\[ d(i,j)=\\dfrac{|x_i-x_j|}{|x_i|+|x_j|} \\] Ajout d’indicateurs de flux, permettant de mesurer l’intensité des échanges (essentiellement de nature économique) Ajout de variables binaires pour les couples appartenant à un même zonage administratif ou d’étude 2.1 Création des couples de communes Chaque ligne de la base de donnée représente un couple de communes contigües (c’est à dire qu’elle se touchent en au moins un point). La base est donc contstituée de deux colonnes “commune A” et “commune B” et on compte 218 000 couples, mais pour dans lesquels A,B et B,A forment deux lignes distinctes. On crée donc un identifiant unique pour A,B et B,A pour n’avoir qu’une occurrence des couples dans la base. Il y a donc, au final, envrion 109 000 lignes dans la base. ## Var1 Var2 first second ident codgeo1 codgeo2 ## 1 1 25 1 25 1_25 01001 01028 ## 2 1 86 1 86 1_86 01001 01093 ## 3 1 134 1 134 1_134 01001 01146 ## 4 1 172 1 172 1_172 01001 01188 ## 5 1 319 1 319 1_319 01001 01351 ## 6 1 377 1 377 1_377 01001 01412 2.2 Indicateurs communaux mobilisés Pour déterminer les caractéristiques des communes (et ensuite déterminer si elles sont très différentes ou homogènes), nous avons utilisé la base comparateur de de territoires fournie par l’Insee. Celle-ci constitue une synthèses de diverses sources de données (recensement de la population, Connaissance locale de l’appareil production, fichiers d’état civil, fichiers fiscaux…). Certaines variables de cette base sont présentes pour 2008 et 2013, ce qui nous a permis de calculer des évolutions en plus des stocks. On a également ajouté la variable de densité de population (hab/km²) A cette base, on ajoute quelques indicateurs supplémentaires : - Revenu médian communal (Source : Filocom2015). Attention, données à ne pas diffuser - Potentiel financier de la commune (Source : DGCL). Le potentiel financier indique le montant des recettes fiscal que percevrait la commune si elle pratique les taux de prélèvement moyens. C’est un proxy de la “richesse” des communes. 2.3 Indicateurs de flux Pour mesurer l’intensité des liens entre les communes contigües, notamment les échanges économiques, nous avons rassemblé 4 indicateurs bilocalisés : Le nombre d’actifs se déplaçant de la commune A à la commune B (et réciproquement) (source : RP2013) Le nombre de migrations résidentielles entre les deux communes A et B intervenues entre 2012 et 2013 (source : RP2013) Le nombre de logements en location de la commune A détenus par des propriétaires de la commune B et réciproquement (source : filocom2015) Attention, données à ne pas diffuser -Le nombre de résidences secondaires de la commune A détenus par les propriétaires habitant la commune B et réciproquement (source : filocom2015) Attention, données à ne pas diffuser 2.4 Appartenance à un même périmètre Enfin, nous avons créé des variables binaires d’appartenance à un même périmètre géogpraphique. Ces variables valent 1 si les communes A et B appartiennent aux mêmes : Etablissement public de coopération intercommunale (EPCI, eg communautés de communes), contours 2014 et 2016 Département Zone d’emploi (Insee) Bassin de vie (Insee) Aire urbaine (Insee) Schéma de cohérence territoriale (document d’urbanisme supracommunal) Plan local d’urbanisme intercommunal Ceci permet de mesurer la proximité institutionnelle (périmètres administratif) et fonctionnelle (zonages d’études de l’Insee) des communes. 2.5 Détermination de la couleur politique des communes 2.5.1 Un proxy de la couleur politique d’une commune Pour alimenter le modèle de machine learning, une variable qui semble, a priori, très importante, est la proximité politique entre chaque couple de communes ; on peut penser que si les mairies, avant la fusion, ont des couleurs semblables, la probabilité d’un accord de fusion entre les deux communes est plus grande. N’ayant à disposition aucune donnée vraiment structurée concernant la couleur politique de telle ou telle mairie, nous avons opté pour l’analyse des résultats des élections présidentielles du premier tour de 2017. L’hypothèse est que les votes des électeurs lors de l’élection nationale donne un proxy raisonnable de l’orientation locale. Cette hypothèse est naturellement simplificatrice et n’est pas valable partout (implantation locale d’une personnalité, absence d’étiquette des élus locaux…). Les données sont disponibles sur data.gouv.fr et proviennent du ministère de l’intérieur. Le choix s’est porté sur le premier tour dans la mesure où celui-ci contient plus de variance, puisque davantage de candidats. 2.5.2 Préparation des données Avant de démarrer, il faut installer le package COGugaison, qui permet de passer facilement d’un millésime de géographique comunale à un autre. On charge en plus les packages du tidyverse, FactoMineR pour l’analyse des données, et sf pour la gestion des données géographiques. On charge également le fonds de carte communale de l’IGN. Pour le fonds de carte, il faut passer des arrondissements (Paris, Lyon, Marseille) à la commune (on ne dispose pas des informations à l’arrondissement dans la plupart des cas) Les données initiales se présentent comme un fichier de 36000 lignes avec pour chaque candidats 7 colonnes donnant notamment le nom, prénom, nombre de voix et les pourcentages correspondants. Le premier travail consiste à passer de ce format “large” inexploitable à un format “long” qui aura un ligne pour chaque croisement commune*candidat avec en colonne le nombre de voix. On gère également le millésime du COG en se ramenant au COG2015 comme pour les autres variables que l’on ajoute par la suite. 2.5.3 Analyse factorielle des résultats Maintenant que nous disposons d’une table exploitable, on peut réaliser une analyse factorielle pour pouvoir synthétiser le positionnement politique des communes. Pour cela, on effectue une analyse factorielle des correspondance, puisqu’on dispose de 2 variables qualitatives : la commune (individus lignes dans le tableau de contingence) et le candidat (individus colonne). D’après l’histogramme des valeurs propres, on voit que l’inertie du tableau de contingence est très concentrée sur les 2 premiers axes factoriels, à hauteur de 70%. Le critère du point d’inflexion conduirait à retenir les 4 premiers axes (la dérivée seconde change de signe au niveau de la 4e valeur propre), pour 87% de l’inertie totale. On observe un effet Guttman assez net sur le premier plan factoriel : on a une opposition nette entre les candidats extrêmes à droite et les candidats “modérés” sur la gauche. Le second axes semble davantage retracer le clivage gauche-droite, avec les candidats Macron et Le Pen proche du barycentre. Le dexième plan factoriel donne lui à voir des différences moins structurantes à l’échelle nationale, mais on voit nettement la particularité “locale” du vote Lassalle, ainsi que (dans une moindre mesure) de celui en faveur de Dupont-Aignan. La représentation cartographique de ces axes factoriels : 2.5.4 Synthèse : typologie communale Pour la suite des opérations (modélisation de fusion/ non fusion), nous allons garder les 4 variables quantitatives obtenues par l’AFC mais pour pousser la démarche jusqu’au bout, nous réalisons une classification (clustering) des communes à partir des coordonnées factorielles obtenues. Etant donnés le nombre d’individus et le manque de puissance de la machine sur laquelle je travaille (4Go de RAM), une CAH est impossible (sauf à faire un premier k-means pour diminuer la dimension…), nous réalisons donc un clustering avec l’algorithme k-means puis dbscan Le gain de variance inter-classes augmente très rapidement quand on agmente le nombre de classe, mais le gain marginal s’atténue assez rapidement. On retient donc 5 classes, qui retracent près de 60% de la variance totale des quatre variables. 2.6 Synthèse : Dictionnaire des variables La base compte au final 48 variables : ## [1] &quot;ident&quot; &quot;first&quot; &quot;second&quot; ## [4] &quot;dist_P13_POP&quot; &quot;dist_SUPERF&quot; &quot;dist_P13_MEN&quot; ## [7] &quot;dist_NAISD15&quot; &quot;dist_DECESD15&quot; &quot;dist_P13_LOG&quot; ## [10] &quot;dist_P13_RP&quot; &quot;dist_P13_RSECOCC&quot; &quot;dist_P13_LOGVAC&quot; ## [13] &quot;dist_P13_RP_PROP&quot; &quot;dist_NBMENFISC13&quot; &quot;dist_PIMP13&quot; ## [16] &quot;dist_MED13&quot; &quot;dist_TP6013&quot; &quot;dist_P13_EMPLT&quot; ## [19] &quot;dist_P13_EMPLT_SAL&quot; &quot;dist_P13_POP1564&quot; &quot;dist_P13_CHOM1564&quot; ## [22] &quot;dist_P13_ACT1564&quot; &quot;dist_ETTOT14&quot; &quot;dist_ETAZ14&quot; ## [25] &quot;dist_ETBE14&quot; &quot;dist_ETFZ14&quot; &quot;dist_ETGU14&quot; ## [28] &quot;dist_ETGZ14&quot; &quot;dist_ETOQ14&quot; &quot;dist_ETTEF114&quot; ## [31] &quot;dist_ETTEFP1014&quot; &quot;dist_revmoy&quot; &quot;dist_pot_fin&quot; ## [34] &quot;dist_Pol1&quot; &quot;dist_Pol2&quot; &quot;dist_evol_pop&quot; ## [37] &quot;dist_densite&quot; &quot;dist_evol_nais&quot; &quot;dist_evol_dec&quot; ## [40] &quot;dist_evol_empl&quot; &quot;nb_locprop&quot; &quot;nb_RS&quot; ## [43] &quot;nb_mig&quot; &quot;nb_navettes&quot; &quot;dep&quot; ## [46] &quot;ze&quot; &quot;bv&quot; &quot;au&quot; ## [49] &quot;epci2014&quot; &quot;epci2016&quot; &quot;scot&quot; ## [52] &quot;plui&quot; &quot;fusion_2016&quot; &quot;fusion_2015&quot; ## [55] &quot;fusion&quot; Le préfixe “dist_” indique qu’il s’agit d’un indicateur de dissimilarité. Le préfixe “nb_” indique qu’il s’agit d’un indicateur de flux. Les variables non préfixées sont les variables binaires d’appartenance géographique. P13_POP : Population en 2013 SUPERF : Superficie (en km2) P13_MEN : Nombre de ménages en 2013 NAISD15 : Nombre de naissances domiciliées en 2015 DECESD15 : Nombre de décès domiciliés en 2015 P13_LOG : Nombre de logements en 2013 P13_RP : Nombre de résidences principales en 2013 P13_RSECOCC : Nombre de résidences secondaires et logements occasionnels en 2013 P13_LOGVAC : Nombre de logements vacants en 2013 P13_RP_PROP : Nombre de résidences principales occupées par propriétaires en 2013 NBMENFISC14 : Nombre de ménages fiscaux en 2013 PIMP13 : Part des ménages fiscaux imposés en 2013 MED14 : Médiane du niveau de vie en 2013 TP6014 : Taux de pauvreté en 2013 P13_EMPLT : Nombre d’emplois au lieu de travail en 2013 P13_EMPLT_SAL : Nombre d’emplois salariés au lieu de travail en 2013 P09_EMPLT : Nombre d’emplois au lieu de travail en 2009 P13_POP1564 : Nombre de personnes de 15 à 64 ans en 2013 P13_CHOM1564 : Nombre de chômeurs de 15 à 64 ans en 2013 P13_ACT1564 : Nombre de personnes actives de 15 à 64 ans en 2013 ETTOT14 : Total des établissements actifs au 31 décembre 2014 ETAZ14 : Etablissements actifs de l’agriculture, sylviculture et pêche au 31/12/2014 ETBE14 : Etablissements actifs de l’industrie au 31/12/2014 ETFZ14 : Etablissements actifs de la construction au 31/12/2014 ETGU14 : Etablissements actifs du commerce, transports et services divers au 31/12/2014 ETGZ14 : Etablissements actifs du commerce et réparation automobile au 31/12/2014 ETOQ14 : Etablissements actifs de l’administration publique, enseignement, santé et action sociale au 31/12/2014 ETTEF114 : Etablissements actifs de 1 à 9 salariés au 31 décembre 2014 ETTEFP1014 : Etablissements actifs de 10 salariés ou plus au 31 décembre 2014 revmoy : Revenu médian par unité de consommation pot_fin : Potentiel financier de la commune (ressources fiscal si elle applique les taux de prélèvement moyens) Pol1 : Premier axe facttoriel de l’AFC sur les résultats électoraux (présidentielles 2017, tour 1) Pol2 : Deuxième axe facttoriel de l’AFC sur les résultats électoraux (présidentielles 2017, tour 1) evol_nais : évolution du nombre de naissances entre 2013 et 2015 evol_dec : évolution du nombre de décès entre 2013 et 2015 evol_pop : évolution de la population entre 2008 et 2013 evol_empl : évolution du nombre d’emplois au lieu de travail entre 2008 et 2013 RS : nombre de résidences secondaires de la commune A détenus par un propriétaire de la commune B (et réciproquement) loc_prop : nombre de logements loués de la commune A détenus par un propriétaire de la commune B (et réciproquement) mig : nombre de migrations résidentielles (déménagements) de la commune A vers la commune B (et réciproquement) navettes : nombre de déplacements domicile-travail de la commune A vers la commune B (et réciproquement) dep : appartenance au même département ze : appartenance à la même zone d’emploi bv : appartenance au même bassin de vie au : appartenance à la même aire urbaine epci2014 : appartenance au même EPCI (contour 2014) epci2016 : appartenance au même EPCI (contour 2016) scot : appartenance au même SCOT (schéma de cohérence territoriale) plui : appartenance au même plan local d’urbanisme intercommunal 2.7 Imputations et corrections Afin d’avoir une base opérationnelle pour la partie statistiques descriptives et machine learning, nous avons enfin nettoyé les données : nous avons supprimé les variables pour lesquelles la part de données manquante était trop importante (&gt;3%), imputé les valeurs manquantes par la moyenne, et remplacé les distances “infinies” (causée par une valeur nulle d’un indicateur pour une commune) par le maximum observé sur les autres lignes. 2.8 Calcul de l’indicateur de fusion Etant donné que nous cherchons à prédire la fusion des couples de communes, nous allons créer une variable indicatrice de fusion. Pour cela, nous utilisons de nouveau le package COGugaison. Nous prenons la base qui recense, d’une année à l’autre, les fusions / défusions. Dans notre cas, nous prenons les années 2015-2016 et 2016-2017 ainsi que les variables codgeo_2016, codgeo_2017 et typemodif. ## cod2016 cod2017 annee typemodif ratio ## 1 76676 76601 2017-01-01 d 0.3236074 ## 2 76676 76676 2017-01-01 d 0.6763926 ## 3 01095 01095 2017-01-01 f 1.0000000 ## 4 01172 01095 2017-01-01 f 1.0000000 ## 5 01098 01098 2017-01-01 f 1.0000000 ## 6 01316 01098 2017-01-01 f 1.0000000 Puis, nous filtrons uniquement sur les fusions. Nous splitons les bases afin de recréer les couples de communes et nous ne gardons que les couples différents Enfin, nous créons un indicateur de fusion sur chaque base qui vaut “1” quand il y a fusion “0” sinon. Puis nous réintégrons l’information dans notre base de travail Nous avons donc: ## type_fusion annee_2015_2017 annee_2015_2016 annee_2016_2017 ## 1 0 107308 107972 108418 ## 2 1 1774 1110 664 Les fusions représentent 1 774 couples de communes sur 109 082 au total soit 1,6 % de la base. Ce qui est très faible. "],
["analyse-des-features.html", "Chapitre 3 Analyse des features 3.1 La variable de distance sur la population: dist_P13_POP 3.2 La variable sur l’appartenance politique: dist_Pol1 3.3 La variable du nombre de navettes inter-communes : nb_navettes 3.4 Matrice des corrélations 3.5 Clustering", " Chapitre 3 Analyse des features Nous regardons la distribution d’une variable de chaque grande famille de données 3.1 La variable de distance sur la population: dist_P13_POP On constate qu’il y a beaucoup de couple de communes qui ont une faible différence de population lors de la non-fusion. On retrouve le cas pour les communes rurales ou les grandes villes. 3.2 La variable sur l’appartenance politique: dist_Pol1 On constate, sur les non-fusions, une grande disparité des valeurs, ce qui n’est pas le cas pour la fusion. Ce qui confirmerait que les communes ayant fusionné ont une même tendance politique. 3.3 La variable du nombre de navettes inter-communes : nb_navettes Nous sommes passés au logarithme afin de mieux visualiser la distribution, très asymétrique. 3.4 Matrice des corrélations On constate qu’il n’y a pas de corrélations linéaires entre les variables de distances et les variables de nb. On voit qu’il y a des corrélations entre certaines variables. Par exemple, dist_P13_POP et dist_P13_LOC. On garde toutes les variables afin de ne pas supprimer de la variance. Avant de lancer les méthodes de ML, nous allons faire du clustering afin de voir s’il n’existerait pas de clusters de couples de communes. 3.5 Clustering Etant donné le nombre important de lignes et la faible capacité de la machine. Nous ne ferons pas de CAH puis un K-means mais un k-means directement. Nous aurions ?galement pu faire un k-means pour diminuer le nombre de lignes et ensuite effectuer une CAH pour maximiser l’inertie interclasse (alors que le k-means minimise l’inertie intraclasse) On voit que la variance intraclasse stagne à partir de 6 classes. On voit qu’avec les 6 classes, on retrace près de 90% de la variance totale On affecte, à chaque couple de communes, son cluster d’appartenance et on regarde dans chaque cluster la répartition de la variable fusion ## ## Fusion Non Fusion Sum ## cluster 1 5 333 338 ## cluster 2 0 77 77 ## cluster 3 11 1832 1843 ## cluster 4 0 8 8 ## cluster 5 0 20 20 ## cluster 6 1758 105038 106796 ## Sum 1774 107308 109082 On constate que le cluster 1 contient la quasi-totalité des fusions. De plus, cette classe est marquée est consituée par les couples de communes les plus semblables : cl_class dist_P13_POP dist_SUPERF dist_P13_MEN dist_P13_LOG dist_P13_RP dist_P13_RSECOCC dist_P13_LOGVAC dist_P13_RP_PROP dist_P13_EMPLT dist_P13_EMPLT_SAL dist_P13_POP1564 dist_P13_CHOM1564 dist_P13_ACT1564 dist_ETTOT14 dist_ETAZ14 dist_ETFZ14 dist_ETGU14 dist_ETOQ14 dist_ETTEF114 dist_revmoy dist_pot_fin dist_Pol1 dist_Pol2 dist_evol_pop dist_densite dist_evol_empl nb_locprop nb_RS nb_mig nb_navettes cluster 1 0.6528698 0.4429754 0.6713167 0.6772515 0.6713167 0.7720173 0.7383863 0.6068453 0.7092862 0.7117465 0.6596341 0.7060974 0.6525772 0.6900375 0.5166939 0.6292465 0.6988026 0.7117091 0.6946497 0.0946899 0.6645955 0.4251332 0.5655192 0.0245313 0.4671913 0.0378124 409.076923 39.1775148 402.425777 2254.08311 cluster 2 0.7717572 0.5548627 0.7889639 0.7954441 0.7889639 0.8777274 0.8486011 0.7325376 0.8183085 0.8191151 0.7817643 0.8124234 0.7780262 0.8114469 0.6182068 0.7603281 0.8206782 0.8056679 0.8133097 0.1048239 0.7846550 0.3045638 0.6232960 0.0221584 0.4138208 0.0270296 1084.038961 99.2597403 909.003520 5286.95352 cluster 3 0.5692132 0.3751107 0.5846876 0.5891793 0.5846876 0.6257900 0.6416092 0.5262392 0.6471399 0.6536227 0.5689283 0.6269799 0.5638316 0.5939463 0.4518727 0.5480083 0.6067305 0.6319027 0.6147784 0.0911368 0.5936009 0.4275222 0.5645617 0.0275561 0.4638924 0.0519686 118.395551 11.9506240 131.788638 643.78620 cluster 4 0.8820297 0.8510783 0.8919122 0.8957517 0.8919122 0.9331496 0.9084888 0.8826418 0.9006597 0.8969974 0.8857381 0.8730461 0.8853207 0.9236429 0.9439857 0.8665048 0.9279170 0.9216889 0.9289184 0.1962382 0.8913489 0.1345052 0.7434921 0.0125245 0.1722364 0.0317686 5742.625000 678.7500000 3299.405619 26673.71041 cluster 5 0.8483371 0.6820082 0.8692100 0.8750354 0.8692100 0.9494309 0.9127921 0.8267928 0.8472004 0.8427063 0.8574374 0.8595356 0.8530972 0.8874141 0.7631278 0.8218592 0.8943663 0.8883098 0.8812697 0.1623373 0.8511275 0.2511565 0.6189600 0.0133818 0.3522964 0.0246086 2305.850000 206.8500000 1673.812391 12578.32912 cluster 6 0.3948445 0.2906449 0.3956746 0.3882293 0.3956746 0.4130290 0.4612233 0.3785998 0.5022158 0.5629996 0.3927604 0.4470152 0.3909049 0.3974463 0.3622695 0.4939238 0.4618564 0.4290194 0.4555829 0.0646239 0.4128903 0.4546936 0.5442040 0.0437398 0.3158759 0.1297288 3.129986 0.5201225 4.440111 15.21377 "],
["modelisation-de-la-probabilite-de-fusionner.html", "Chapitre 4 Modélisation de la probabilité de fusionner", " Chapitre 4 Modélisation de la probabilité de fusionner Après nettoyage et sélection des features, la base de données pour exécuter le machine learning est donc constituée de 109082 observations et de 38 variables explicatives. ## [1] &quot;dep&quot; &quot;ze&quot; &quot;bv&quot; ## [4] &quot;au&quot; &quot;epci2014&quot; &quot;epci2016&quot; ## [7] &quot;scot&quot; &quot;plui&quot; &quot;dist_P13_POP&quot; ## [10] &quot;dist_SUPERF&quot; &quot;dist_P13_MEN&quot; &quot;dist_P13_LOG&quot; ## [13] &quot;dist_P13_RP&quot; &quot;dist_P13_RSECOCC&quot; &quot;dist_P13_LOGVAC&quot; ## [16] &quot;dist_P13_RP_PROP&quot; &quot;dist_P13_EMPLT&quot; &quot;dist_P13_EMPLT_SAL&quot; ## [19] &quot;dist_P13_POP1564&quot; &quot;dist_P13_CHOM1564&quot; &quot;dist_P13_ACT1564&quot; ## [22] &quot;dist_ETTOT14&quot; &quot;dist_ETAZ14&quot; &quot;dist_ETFZ14&quot; ## [25] &quot;dist_ETGU14&quot; &quot;dist_ETOQ14&quot; &quot;dist_ETTEF114&quot; ## [28] &quot;dist_revmoy&quot; &quot;dist_pot_fin&quot; &quot;dist_Pol1&quot; ## [31] &quot;dist_Pol2&quot; &quot;dist_evol_pop&quot; &quot;dist_densite&quot; ## [34] &quot;dist_evol_empl&quot; &quot;nb_locprop&quot; &quot;nb_RS&quot; ## [37] &quot;nb_mig&quot; &quot;nb_navettes&quot; On découpe cette base en 12 blocs de lignes qui vont permettre de réaliser la validation croisée. On a également implémenté une fonction qui permet d’entrainer puis de tester les modèles suivants : régression logistique régression logistique avec choix de variables par AIC (step) régressions pénalisées (lasso, ridge, elasticnet) arbre de décision boosting (adaboost) forêt aléatoire SVM (mais n’ont pas abouti) Réseaux de neurones 3 couches connectées de façon complète avec respectivement 10, 20 et 10 neurones 4 couches connectées de façon complète avec respectivement 1024, 640, 120 et 12 neurones La fonction est appelée dans une boucle foreach qui permet de paraléliser les traitements pour chaque bloc. On a ainsi pu diviser les temps de calcul par 3 (pour les modèles entrainés sur nos postes) ou par 7 (pour les modèles entraînés sur un serveur). Le résultat de cette boucle est un dataframe contenant les prévisions (probabilités) faites par les différents modèles sur les blocs de tests. Les résultats sont présentés dans l’application shiny dédiée au projet (courbes ROC, indicateur AUC et matrices de confusion). Globalement, on constate que les modèles à base d’arbres de décisions donnent de meilleurs résultat : il semble que le choix de fusionner soit déterministe, et guidé les proximités en termes de vote des habitants (vote modéré ou extrême). On peut penser que cette variable détermine également les habitudes collaboratives des communes, c’est à dire leur appartenance à une même structure intercommunale (EPCI, SCOT), et que les communes ayant des électorats proches peuvent plus facilement se regrouper dans le cadre d’un projet commun. ## $ARBRE ## ## Call: ## roc.default(response = prev$Y, predictor = x) ## ## Data: x in 107308 controls (prev$Y 0) &lt; 1774 cases (prev$Y 1). ## Area under the curve: 0.9999 ## ## $FORET ## ## Call: ## roc.default(response = prev$Y, predictor = x) ## ## Data: x in 107308 controls (prev$Y 0) &lt; 1774 cases (prev$Y 1). ## Area under the curve: 0.9999 ## ## $DNN1 ## ## Call: ## roc.default(response = prev$Y, predictor = x) ## ## Data: x in 107308 controls (prev$Y 0) &lt; 1774 cases (prev$Y 1). ## Area under the curve: 0.992 ## ## $DNN2 ## ## Call: ## roc.default(response = prev$Y, predictor = x) ## ## Data: x in 107308 controls (prev$Y 0) &lt; 1774 cases (prev$Y 1). ## Area under the curve: 0.9008 ## $ARBRE ## NULL ## ## $FORET ## NULL ## ## $DNN1 ## NULL ## ## $DNN2 ## NULL ## $Y ## [1] 1774 ## ## $ARBRE ## [1] 1789 ## ## $FORET ## [1] 1788 ## ## $DNN1 ## [1] 931 ## ## $DNN2 ## [1] 1043 L’arbre de décision seul produisant déjà des résultats très satisfaisants, les forêts aléatoires et adaboost l’améliorent, mais légèrement. Les autres méthodes sont moins performantes. La régression par exemple, ne met autant en avant le pouvoir discriminant de la proximité politique ## ## Call: ## glm(formula = y ~ ., family = binomial, data = baseML) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -4.0191 0.0000 0.0000 0.0000 0.7418 ## ## Coefficients: (1 not defined because of singularities) ## Estimate Std. Error z value Pr(&gt;|z|) ## (Intercept) 1.184e+01 4.877e+02 0.024 0.9806 ## dep1 1.457e+00 1.602e+03 0.001 0.9993 ## ze1 1.705e+01 1.515e+03 0.011 0.9910 ## bv1 4.872e+00 1.923e+02 0.025 0.9798 ## au1 -1.450e+00 7.374e-01 -1.967 0.0492 * ## epci20141 -9.486e+00 8.016e+01 -0.118 0.9058 ## epci20161 -1.151e+01 8.198e+01 -0.140 0.8883 ## scot1 -7.740e+00 1.682e+01 -0.460 0.6454 ## plui1 1.334e+00 7.452e-01 1.790 0.0735 . ## dist_P13_POP -6.684e+00 1.140e+01 -0.586 0.5575 ## dist_SUPERF -4.564e+00 1.980e+00 -2.305 0.0212 * ## dist_P13_MEN -1.258e+01 1.105e+01 -1.139 0.2547 ## dist_P13_LOG 1.251e+01 6.525e+00 1.917 0.0553 . ## dist_P13_RP NA NA NA NA ## dist_P13_RSECOCC -6.543e-01 1.250e+00 -0.523 0.6007 ## dist_P13_LOGVAC -2.153e+00 1.451e+00 -1.484 0.1379 ## dist_P13_RP_PROP 1.141e+01 6.553e+00 1.742 0.0816 . ## dist_P13_EMPLT -1.965e+00 3.953e+00 -0.497 0.6190 ## dist_P13_EMPLT_SAL 1.088e+00 3.395e+00 0.321 0.7486 ## dist_P13_POP1564 -2.263e+01 1.330e+01 -1.701 0.0889 . ## dist_P13_CHOM1564 -2.185e+00 1.913e+00 -1.142 0.2533 ## dist_P13_ACT1564 1.891e+01 1.060e+01 1.784 0.0744 . ## dist_ETTOT14 2.597e+00 3.689e+00 0.704 0.4814 ## dist_ETAZ14 8.393e-01 1.360e+00 0.617 0.5371 ## dist_ETFZ14 -1.533e+00 1.175e+00 -1.305 0.1920 ## dist_ETGU14 5.594e-01 2.023e+00 0.276 0.7822 ## dist_ETOQ14 1.419e+00 1.540e+00 0.922 0.3567 ## dist_ETTEF114 -9.311e-01 1.634e+00 -0.570 0.5689 ## dist_revmoy 2.917e+00 7.553e+00 0.386 0.6994 ## dist_pot_fin 2.720e+00 4.750e+00 0.573 0.5669 ## dist_Pol1 -5.324e+03 7.187e+03 -0.741 0.4588 ## dist_Pol2 -3.438e+03 5.901e+03 -0.583 0.5601 ## dist_evol_pop 2.786e+00 7.255e+00 0.384 0.7009 ## dist_densite 1.519e+00 1.628e+00 0.933 0.3508 ## dist_evol_empl 3.608e+00 3.031e+00 1.190 0.2340 ## nb_locprop -3.050e-02 8.604e-02 -0.354 0.7230 ## nb_RS 4.327e-01 5.531e-01 0.782 0.4340 ## nb_mig -2.062e-02 4.254e-02 -0.485 0.6279 ## nb_navettes 1.252e-02 1.878e-02 0.667 0.5050 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for binomial family taken to be 1) ## ## Null deviance: 18132.72 on 109081 degrees of freedom ## Residual deviance: 122.83 on 109044 degrees of freedom ## AIC: 198.83 ## ## Number of Fisher Scoring iterations: 25 "],
["conclusion.html", "Chapitre 5 Conclusion", " Chapitre 5 Conclusion Le choix des communes de fusionner apparaît donc comme largement détemriniste : les habitudes anciennes de travail en commun des communes dans des structures administratives priment les ressemblances sur le plan socio-économiques et les flux qui les unissent.C’est pourquoi les modèles basés sur des arbres de décisionsont à même de prédire de façon très fidèle les fusions de communes Après ce travail, plusieurs pistes pourraient être explorées pour en augmenter la portée : Appliquer le résultat de ces modèles sur les données plus récentes portant sur le millésime 2017 de la géographie communale Restreindre le machine learning au seul cluster de couples de communes très semblables Dupliquer, avec brouillage, les lignes correspondant aux couple fusionnés dans la base d’apprentissage Traiter les données aberrantes et influentes, faire un peu plus de feature ingineering pour augementer la qualité des modèles basés sur la régression Implémenter les SVM Faire la partie ML sous python …? "]
]
